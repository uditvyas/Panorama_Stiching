{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-parks",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-milan",
   "metadata": {},
   "source": [
    "### The following are helpers functions to find the SIFT features and find matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modular-flight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract SIFT like keypoints and corresponding descriptors from the image\n",
    "def extract_features_keypoints(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    orb = cv2.ORB_create()\n",
    "    (Keypoints, features) = orb.detectAndCompute(image, None)\n",
    "    return (Keypoints, features)\n",
    "\n",
    "# Function to match the Features in two images using Brute force, KNN matcher (default K = 2)\n",
    "def match_features(features1, features2, K=2):\n",
    "    matcher = cv2.BFMatcher()\n",
    "    matches = matcher.knnMatch(features1, features2, K)\n",
    "    return matches\n",
    "\n",
    "\n",
    "# Function to find high confidence matches using the Lowe's ratio rule (default ratio test = 0.8)\n",
    "def valid_matches(matches, lowe_ratio=0.8):\n",
    "    valid_matches = []\n",
    "\n",
    "    for k_match in matches:\n",
    "        if len(k_match) == 2 and k_match[0].distance < k_match[1].distance * lowe_ratio:\n",
    "            valid_matches.append(k_match[0])\n",
    "    return valid_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-terrace",
   "metadata": {},
   "source": [
    "### The following functions are helpers to the finding the Homography matrix between two images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-gossip",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to prepare the keypoints based on the matches, to feed as an input to the RANSAC Algorithm\n",
    "def correspondence_matrix(valid_matches, ref_keypoints, tar_keypoints):\n",
    "    keypoints = []\n",
    "\n",
    "    for match in valid_matches:\n",
    "        (x0, y0) = ref_keypoints[match.queryIdx].pt\n",
    "        (x1, y1) = tar_keypoints[match.trainIdx].pt\n",
    "        keypoints.append([x0, y0, x1, y1])\n",
    "\n",
    "    return keypoints\n",
    "\n",
    "# Function to calculate a homography matrix from 4 samples provided, using SVD\n",
    "def calcH(sample):\n",
    "    A = []\n",
    "    for x, y, xx, yy in sample:\n",
    "\n",
    "        first = [x, y, 1, 0, 0, 0, -xx*x, -xx*y, -xx]\n",
    "        second = [0, 0, 0, x, y, 1, -yy*x, -yy*y, -yy]\n",
    "\n",
    "        A.append(first)\n",
    "        A.append(second)\n",
    "\n",
    "    A = np.matrix(A)\n",
    "    U, S, V = np.linalg.svd(A)\n",
    "\n",
    "    H = np.reshape(V[8], (3, 3))\n",
    "    # Normalising\n",
    "    H = (1/H[2, 2])*H\n",
    "    return H\n",
    "\n",
    "\n",
    "# Function to find error, by finding the difference between the projected value and the actual value\n",
    "def findError(matrixRow, H):\n",
    "    point1 = np.transpose(np.array([matrixRow[0], matrixRow[1], 1]))\n",
    "    point2 = np.array([matrixRow[2], matrixRow[3], 1])\n",
    "    estimate = np.dot(H, point1)\n",
    "    estimate = estimate/estimate[0, 2]\n",
    "    error = point2 - estimate\n",
    "    return np.linalg.norm(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convinced-scanning",
   "metadata": {},
   "source": [
    "### RANSAC Algorithm to find the Homography Matrix between a pair of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-degree",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function implementing the RANSAC Algorithm ()\n",
    "def get_homography(matrix, n_iter=3000):\n",
    "    inliers = []\n",
    "    n = len(matrix)\n",
    "    finalH = None\n",
    "    for i in tqdm(range(n_iter)):\n",
    "        indices = random.sample(range(1, n), 4)\n",
    "        random_sample = [matrix[i] for i in indices]\n",
    "\n",
    "        H = calcH(random_sample)\n",
    "        iteration_inliers = []\n",
    "\n",
    "        for i in range(n):\n",
    "            error = findError(matrix[i], H)\n",
    "            if error < 2:\n",
    "                iteration_inliers.append(matrix[i])\n",
    "\n",
    "        if len(iteration_inliers) > len(inliers):\n",
    "            inliers = iteration_inliers\n",
    "            finalH = H\n",
    "\n",
    "    return finalH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorrect-packing",
   "metadata": {},
   "source": [
    "### Helper Function to combine the codes so far, to generate the final homography matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dangerous-nickname",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper helper Function to find the Homography matrix\n",
    "def stitch(reference, target):\n",
    "    (reference_keypoints, reference_features) = extract_features_keypoints(reference)\n",
    "    (target_keypoints, target_features) = extract_features_keypoints(target)\n",
    "    all_matches = match_features(reference_features, target_features)\n",
    "    good_matches = valid_matches(all_matches)\n",
    "    keypoint_matrix = correspondence_matrix(good_matches, reference_keypoints, target_keypoints)\n",
    "\n",
    "    H = get_homography(keypoint_matrix)\n",
    "    return np.array(H)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geographic-desktop",
   "metadata": {},
   "source": [
    "### Helper Function to warp two images, when provided with the reference, target, and Homography matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-valley",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to warp an image, and add it to the output image generated using the previous function\n",
    "# This function also generates a mask of common values between the stitched image so far, and the new warped image\n",
    "# The function returns the original image, the separate warped image, and as well as the mask as the output\n",
    "def mywarp(output, target, x_offset, y_offset, H):\n",
    "    out = output.copy()\n",
    "    output_copy = np.zeros_like(output)\n",
    "    h = target.shape[0]\n",
    "    w = target.shape[1]\n",
    "    \n",
    "    # Finding the bounding rectange in the transformed plane.\n",
    "    corners = [[0,0,1],[h-1,0,1],[0,w-1,1],[h-1,w-1,1]]\n",
    "    transform_corners = np.array([H.dot(np.array(corner).T) for corner in corners])\n",
    "    transform_corners = [corner/corner[2] for corner in transform_corners]\n",
    "    xs = [corner[1] for corner in transform_corners]\n",
    "    ys = [corner[0] for corner in transform_corners]\n",
    "    xmin, xmax = int(np.min(xs)), int(np.max(xs))+1\n",
    "    xmin = max(xmin, -x_offset)\n",
    "    xmax = min(xmax + x_offset, output_copy.shape[1])\n",
    "    ymin, ymax = int(np.min(ys)), int(np.max(ys))+1\n",
    "    ymin = min(ymin, -y_offset)\n",
    "    ymax = min(ymax + y_offset, output_copy.shape[0])\n",
    "\n",
    "    invH = np.linalg.inv(H)\n",
    "    \n",
    "    # Reverse mapping the points in the transformed plane to check if they lie in the original images\n",
    "    for j in tqdm(range(ymin,ymax)):\n",
    "        for i in range(xmin,xmax):\n",
    "            point = np.array([i,j,1]).T\n",
    "            inverse = invH.dot(point)\n",
    "            inverse = inverse/inverse[2]\n",
    "            x = int(inverse[0])\n",
    "            y = int(inverse[1])\n",
    "\n",
    "            if x in range(0,w) and y in range(0,h):\n",
    "                try:\n",
    "                    output_copy[j + y_offset][i + x_offset] = target[y][x]\n",
    "                    output[j + y_offset][i + x_offset] = target[y][x]\n",
    "                except:\n",
    "                    continue\n",
    "    mask = out*output_copy\n",
    "    return mask, out, output_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-garbage",
   "metadata": {},
   "source": [
    "### Helper Function to Blend two images, post warping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-desire",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to blend the newly warped image and the existing stiched image\n",
    "# It makes use of the Image pyraminds to estimate Gaussian and Laplacian pyramids of the two images\n",
    "# and makes used the mask generated in the previous step, to reconstruct the images in order to blend them\n",
    "def blend(A, B, mask, stichOnLeft, levels = 6):\n",
    "    mask = np.where(mask>0, 0, 1)\n",
    "    xmin, xmax = np.min(np.where(mask == 0)[1]), np.max(np.where(mask == 0)[1])\n",
    "    xmid = (xmin + xmax)//2\n",
    "    new_mask = np.zeros_like(A)\n",
    "    \n",
    "    # This is conditional to the stitch being on the right side, or the left side of the reference image.\n",
    "    if stichOnLeft:\n",
    "        new_mask[:, xmid:, :] = 1\n",
    "    else:\n",
    "        new_mask[:, :xmid, :] = 1\n",
    "\n",
    "    # generate Gaussian pyramid for A\n",
    "    G = A.copy()\n",
    "    gpA = [G]\n",
    "    for i in range(levels):\n",
    "        G = cv2.pyrDown(G)\n",
    "        gpA.append(G)\n",
    "\n",
    "    # generate Gaussian pyramid for B\n",
    "    G = B.copy()\n",
    "    gpB = [G]\n",
    "    for i in range(levels):\n",
    "        G = cv2.pyrDown(G)\n",
    "        gpB.append(G)\n",
    "\n",
    "    # generate Gaussian pyramid for the mask\n",
    "    G = new_mask.copy()\n",
    "    gp_new = [G]\n",
    "    for i in range(1,levels):\n",
    "        G = cv2.pyrDown(G)\n",
    "        gp_new.append(G)\n",
    "\n",
    "    # generate Laplacian Pyramid for A\n",
    "    lpA = [gpA[levels-1]]\n",
    "    for i in range(levels-1,0,-1):\n",
    "        GE = cv2.pyrUp(gpA[i], dstsize=(gpA[i-1].shape[1], gpA[i-1].shape[0]))\n",
    "        L = cv2.subtract(gpA[i-1],GE)\n",
    "        lpA.append(L)\n",
    "\n",
    "    # generate Laplacian Pyramid for B\n",
    "    lpB = [gpB[levels-1]]\n",
    "    for i in range(levels-1,0,-1):\n",
    "        GE = cv2.pyrUp(gpB[i], dstsize=(gpB[i-1].shape[1], gpB[i-1].shape[0]))\n",
    "        L = cv2.subtract(gpB[i-1],GE)\n",
    "        lpB.append(L)\n",
    "\n",
    "    LS = []\n",
    "    for la,lb,gp in zip(lpA,lpB, gp_new[::-1]):\n",
    "        ls = gp*la + (1-gp)*lb\n",
    "        LS.append(ls)\n",
    "\n",
    "    # now reconstruct\n",
    "    result = LS[0]\n",
    "    for i in range(1,levels):\n",
    "        result = cv2.pyrUp(result, dstsize=(LS[i].shape[1], LS[i].shape[0]))\n",
    "        result = cv2.add(result, LS[i])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "double-religion",
   "metadata": {},
   "source": [
    "### Function to use inbuilt functions to calculate the Homography matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-fortune",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findH_inbuilt(A, B):\n",
    "    orb = cv2.ORB_create()\n",
    "    aa = cv2.cvtColor(A, cv2.COLOR_BGR2GRAY)\n",
    "    bb = cv2.cvtColor(B, cv2.COLOR_BGR2GRAY)\n",
    "    keyA, desA = orb.detectAndCompute(aa, None)\n",
    "    keyB, desB = orb.detectAndCompute(bb, None)\n",
    "    matcher = cv2.BFMatcher()\n",
    "    matches = matcher.knnMatch(desA, desB, 2)\n",
    "    valid_matches = []\n",
    "    lowe_ratio = 0.8\n",
    "    for k_match in matches:\n",
    "        if len(k_match) == 2 and k_match[0].distance < k_match[1].distance * lowe_ratio:\n",
    "            valid_matches.append(k_match[0])\n",
    "    \n",
    "    kA = np.array([keyA[i.queryIdx].pt for i in valid_matches])\n",
    "    kB = np.array([keyB[i.trainIdx].pt for i in valid_matches])\n",
    "    H,mask = cv2.findHomography(kA, kB, cv2.RANSAC)\n",
    "    return H"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "found-valve",
   "metadata": {},
   "source": [
    "### Helper Function to setup the output image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efficient-visit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setReference(image, x_offset, y_offset, x, y):\n",
    "    warped = np.zeros((x, y, 3))\n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            warped[i+y_offset][j+x_offset] = image[i][j]\n",
    "    print(\"Reference Image Set!\")\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weekly-following",
   "metadata": {},
   "source": [
    "### Function to generate the Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "independent-meaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output(images, H21,H32,H42, set_num, useInbuilt):\n",
    "    if set_num==3:\n",
    "        image2, image3, image4 = images\n",
    "    else:\n",
    "        image1, image2, image3, image4 = images\n",
    "    \n",
    "    \n",
    "    height = int(3*image2.shape[0])\n",
    "    width = 5*image2.shape[1]\n",
    "    x_offset = int(1.5*image2.shape[1])\n",
    "    y_offset = int(image2.shape[0])\n",
    "    output = setReference(image2, x_offset, y_offset, height, width)\n",
    "    \n",
    "    if set_num!=3:\n",
    "        mask, original, warped = mywarp(output, image1, x_offset, y_offset, H21)\n",
    "        output = blend(original, warped, mask, stichOnLeft=1)\n",
    "\n",
    "    mask, original, warped =  mywarp(output, image3, x_offset, y_offset, H32)\n",
    "    output = blend(original, warped, mask, stichOnLeft=0)\n",
    "\n",
    "    mask, original, warped =  mywarp(output, image4, x_offset, y_offset, H42)\n",
    "    \n",
    "    # In case of set 6, we avoid the last blend. The blending crops some useful parts of the images,\n",
    "    # due to its unusual stitching direction. Therefore, avoiding it gives more complete picture of the \n",
    "    if set_num!=6:\n",
    "        output = blend(original, warped, mask, stichOnLeft=0)\n",
    "    \n",
    "    if useInbuilt==True:\n",
    "        cv2.imwrite(\"inbuilt_results/inbuilt_\"+str(set_num)+\".png\", output)\n",
    "    else:\n",
    "        cv2.imwrite(\"results/panorama_\"+str(set_num)+\".png\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "printable-newcastle",
   "metadata": {},
   "source": [
    "## Taking Case by Case input, and displaying the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-hobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensuring that the output diretories are present in the directory before starting the execution\n",
    "from os import path, makedirs\n",
    "\n",
    "if not path.exists(\"results/\"):\n",
    "    makedirs(\"results\")\n",
    "if not path.exists(\"inbuilt_results/\"):\n",
    "    makedirs(\"inbuilt_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-agreement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Set 1\n",
    "image1 = cv2.imread(\"inputImages/I1/STC_0033.JPG\")\n",
    "image2 = cv2.imread(\"inputImages/I1/STD_0034.JPG\")\n",
    "image3 = cv2.imread(\"inputImages/I1/STE_0035.JPG\")\n",
    "image4 = cv2.imread(\"inputImages/I1/STF_0036.JPG\")\n",
    "out = 1\n",
    "\n",
    "# RESIZE Set 1\n",
    "image1 = cv2.resize(image1, (800,600))\n",
    "image2 = cv2.resize(image2, (800,600))\n",
    "image3 = cv2.resize(image3, (800,600))\n",
    "image4 = cv2.resize(image4, (800,600))\n",
    "\n",
    "images = [image1, image2, image3, image4]\n",
    "\n",
    "H12 = stitch(image1, image2)\n",
    "H12_inbuilt = findH_inbuilt(image1, image2)\n",
    "\n",
    "H32 = stitch(image3, image2)\n",
    "H32_inbuilt = findH_inbuilt(image3, image2)\n",
    "\n",
    "H43 = stitch(image4, image3)\n",
    "H43_inbuilt = findH_inbuilt(image4, image3)\n",
    "H42 = np.dot(H43, H32)\n",
    "H42_inbuilt = np.dot(H43_inbuilt, H32_inbuilt)\n",
    "\n",
    "print(\"Generating output with Self-made Functions\")\n",
    "generate_output(images, H12, H32, H42, set_num = 1, useInbuilt = False)\n",
    "print(\"Generating output with Inbuilt Functions\")\n",
    "generate_output(images, H12_inbuilt, H32_inbuilt, H42_inbuilt, set_num = 1, useInbuilt = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appreciated-seven",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Set 2\n",
    "image1 = cv2.imread(\"inputImages/I2/2_1.JPG\")\n",
    "image2 = cv2.imread(\"inputImages/I2/2_2.JPG\")\n",
    "image3 = cv2.imread(\"inputImages/I2/2_3.JPG\")\n",
    "image4 = cv2.imread(\"inputImages/I2/2_4.JPG\")\n",
    "out = 2\n",
    "\n",
    "images = [image1, image2, image3, image4]\n",
    "\n",
    "H12 = stitch(image1, image2)\n",
    "H12_inbuilt = findH_inbuilt(image1, image2)\n",
    "\n",
    "H32 = stitch(image3, image2)\n",
    "H32_inbuilt = findH_inbuilt(image3, image2)\n",
    "\n",
    "H43 = stitch(image4, image3)\n",
    "H43_inbuilt = findH_inbuilt(image4, image3)\n",
    "H42 = np.dot(H43, H32)\n",
    "H42_inbuilt = np.dot(H43_inbuilt, H32_inbuilt)\n",
    "\n",
    "print(\"Generating output with Self-made Functions\")\n",
    "generate_output(images, H12, H32, H42, set_num = out, useInbuilt = False)\n",
    "print(\"Generating output with Inbuilt Functions\")\n",
    "generate_output(images, H12_inbuilt, H32_inbuilt, H42_inbuilt, set_num = out, useInbuilt = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-accountability",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Set 3\n",
    "image2 = cv2.imread(\"inputImages/I3/3_3.JPG\")\n",
    "image3 = cv2.imread(\"inputImages/I3/3_4.JPG\")\n",
    "image4 = cv2.imread(\"inputImages/I3/3_5.JPG\")\n",
    "out = 3\n",
    "\n",
    "images = [image2, image3, image4]\n",
    "\n",
    "# All 4 images stitches are not possible in this images, owing to the incorrect features, as explained in the report\n",
    "H12 = None\n",
    "H12_inbuilt = None\n",
    "\n",
    "H32 = stitch(image3, image2)\n",
    "H32_inbuilt = findH_inbuilt(image3, image2)\n",
    "\n",
    "H43 = stitch(image4, image3)\n",
    "H43_inbuilt = findH_inbuilt(image4, image3)\n",
    "H42 = np.dot(H43, H32)\n",
    "H42_inbuilt = np.dot(H43_inbuilt, H32_inbuilt)\n",
    "\n",
    "print(\"Generating output with Self-made Functions\")\n",
    "generate_output(images, H12, H32, H42, set_num = out, useInbuilt = False)\n",
    "print(\"Generating output with Inbuilt Functions\")\n",
    "generate_output(images, H12_inbuilt, H32_inbuilt, H42_inbuilt, set_num = out, useInbuilt = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-litigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Set 4\n",
    "image1 = cv2.imread(\"inputImages/I4/DSC02930.JPG\")\n",
    "image2 = cv2.imread(\"inputImages/I4/DSC02931.JPG\")\n",
    "image3 = cv2.imread(\"inputImages/I4/DSC02932.JPG\")\n",
    "image4 = cv2.imread(\"inputImages/I4/DSC02933.JPG\")\n",
    "out = 4\n",
    "\n",
    "# RESIZE Set 4\n",
    "image1 = cv2.resize(image1, (800,600))\n",
    "image2 = cv2.resize(image2, (800,600))\n",
    "image3 = cv2.resize(image3, (800,600))\n",
    "image4 = cv2.resize(image4, (800,600))\n",
    "images = [image1, image2, image3, image4]\n",
    "\n",
    "H12 = stitch(image1, image2)\n",
    "H12_inbuilt = findH_inbuilt(image1, image2)\n",
    "\n",
    "H32 = stitch(image3, image2)\n",
    "H32_inbuilt = findH_inbuilt(image3, image2)\n",
    "\n",
    "H43 = stitch(image4, image3)\n",
    "H43_inbuilt = findH_inbuilt(image4, image3)\n",
    "H42 = np.dot(H43, H32)\n",
    "H42_inbuilt = np.dot(H43_inbuilt, H32_inbuilt)\n",
    "\n",
    "print(\"Generating output with Self-made Functions\")\n",
    "generate_output(images, H12, H32, H42, set_num = out, useInbuilt = False)\n",
    "print(\"Generating output with Inbuilt Functions\")\n",
    "generate_output(images, H12_inbuilt, H32_inbuilt, H42_inbuilt, set_num = out, useInbuilt = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understanding-player",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Set 5\n",
    "image1 = cv2.imread(\"inputImages/I5/DSC03002.JPG\")\n",
    "image2 = cv2.imread(\"inputImages/I5/DSC03003.JPG\")\n",
    "image3 = cv2.imread(\"inputImages/I5/DSC03004.JPG\")\n",
    "image4 = cv2.imread(\"inputImages/I5/DSC03005.JPG\")\n",
    "out = 5\n",
    "\n",
    "# RESIZE Set 5\n",
    "image1 = cv2.resize(image1, (800,600))\n",
    "image2 = cv2.resize(image2, (800,600))\n",
    "image3 = cv2.resize(image3, (800,600))\n",
    "image4 = cv2.resize(image4, (800,600))\n",
    "images = [image1, image2, image3, image4]\n",
    "\n",
    "H12 = stitch(image1, image2)\n",
    "H12_inbuilt = findH_inbuilt(image1, image2)\n",
    "\n",
    "H32 = stitch(image3, image2)\n",
    "H32_inbuilt = findH_inbuilt(image3, image2)\n",
    "\n",
    "H43 = stitch(image4, image3)\n",
    "H43_inbuilt = findH_inbuilt(image4, image3)\n",
    "H42 = np.dot(H43, H32)\n",
    "H42_inbuilt = np.dot(H43_inbuilt, H32_inbuilt)\n",
    "\n",
    "print(\"Generating output with Self-made Functions\")\n",
    "generate_output(images, H12, H32, H42, set_num = out, useInbuilt = False)\n",
    "print(\"Generating output with Inbuilt Functions\")\n",
    "generate_output(images, H12_inbuilt, H32_inbuilt, H42_inbuilt, set_num = out, useInbuilt = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-grenada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Set 6\n",
    "image1 = cv2.imread(\"inputImages/I6/1_1.JPG\")\n",
    "image2 = cv2.imread(\"inputImages/I6/1_2.JPG\")\n",
    "image3 = cv2.imread(\"inputImages/I6/1_3.JPG\")\n",
    "image4 = cv2.imread(\"inputImages/I6/1_4.JPG\")\n",
    "out = 6\n",
    "images = [image1, image2, image3, image4]\n",
    "\n",
    "H12 = stitch(image1, image2)\n",
    "H12_inbuilt = findH_inbuilt(image1, image2)\n",
    "\n",
    "H32 = stitch(image3, image2)\n",
    "H32_inbuilt = findH_inbuilt(image3, image2)\n",
    "\n",
    "# In this case we find the Homography matrix directly from the reference image (Since there are common features) \n",
    "H42 = stitch(image4, image2)\n",
    "H42_inbuilt = findH_inbuilt(image4, image2)\n",
    "\n",
    "print(\"Generating output with Self-made Functions\")\n",
    "generate_output(images, H12, H32, H42, set_num = out, useInbuilt = False)\n",
    "print(\"Generating output with inbuilt Functions\")\n",
    "generate_output(images, H12_inbuilt, H32_inbuilt, H42_inbuilt, set_num = out, useInbuilt = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-switch",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
